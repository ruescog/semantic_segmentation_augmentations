{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ArtMix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp artmix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# library\n",
    "from semantic_segmentation_augmentations.holemakertechnique import HoleMakerTechnique, HoleMakerRandom\n",
    "from semantic_segmentation_augmentations.regionmodifier import RegionModifier\n",
    "from semantic_segmentation_augmentations.iholesfilling import HolesFilling\n",
    "\n",
    "# others\n",
    "import cv2\n",
    "import random\n",
    "from fastai.basics import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ArtMix(HolesFilling):\n",
    "    \"Defines the amount of holes, the technique used to make them and the probability of apply the technique.\"\n",
    "    def __init__(self,\n",
    "                 mask_path: str, # The path to the image that is going to be used as mask.\n",
    "                 holes_num: int = 1, # The amount of holes to make.\n",
    "                 use_black: bool = True, # Whether to use the black part of the mask or the white part of the mask.\n",
    "                 modifier: \"RegionModifier\" = None, # The modifier that defines the traditional augments to apply to the selected regions.\n",
    "                 hole_maker: \"HoleMakerTechnique\" = None, # The strategy used to make the holes.\n",
    "                 p: float = 0.5): # The probability of applying this technique.\n",
    "        hole_maker = hole_maker if hole_maker else HoleMakerBounded()\n",
    "        super().__init__(modifier, hole_maker)\n",
    "        self.holes_num = holes_num\n",
    "        self.use_black = use_black\n",
    "        self.p = p\n",
    "        \n",
    "        # Converts the mask_img into a mask\n",
    "        mask_img = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        mask_img = np.array(mask_img)\n",
    "        \n",
    "        # It is needed to permute the image because opencv works with a (H,W,C) format\n",
    "        mask_img = mask_img.transpose(1, 0)\n",
    "        hole_size = self.hole_maker.hole_size\n",
    "        # It is needed to interpolate the integers without transforming them into floats\n",
    "        mask_img = cv2.resize(mask_img, hole_size, interpolation = cv2.INTER_LINEAR_EXACT)\n",
    "        mask_img = mask_img.transpose(1, 0)\n",
    "        \n",
    "        # transforms the mask\n",
    "        mask_img[mask_img != 0] = 255\n",
    "        \n",
    "        self.used_value = 0 if use_black else 255\n",
    "        self.mask_img = tensor(mask_img).to(device = \"cuda\")\n",
    "\n",
    "    def before_batch(self):\n",
    "        \"Applies the CutMix technique.\"\n",
    "        \n",
    "        if not self.training:\n",
    "            return\n",
    "        \n",
    "        for image, mask in zip(self.x, self.y):\n",
    "            if random.random() < self.p:\n",
    "                for _ in range(self.holes_num):\n",
    "                    xhole, yhole = self.make_hole(mask)\n",
    "                    sub_image, sub_mask = image[:, yhole, xhole], mask[yhole, xhole]\n",
    "                    # tensor(np.zeros_like(sub_image.cpu())).to(device = \"cuda\")\n",
    "                    image[:, yhole, xhole] = torch.where(self.mask_img[np.newaxis, ...] == self.used_value, torch.min(image), sub_image)\n",
    "                    mask[yhole, xhole] = torch.where(self.mask_img == self.used_value, 0, sub_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TranspareceMix` allows us to fuse two images with the transparence idea. That is: if the overlapping mask has some information (it is not 0 in that position), its value is selected. Otherwise, if the overlapping mask has no information in that pixel, the information of the second image is used to fulfill the final image. Thus allows us to preserve as maximum information as possible, since these information is selected before using the background class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(ArtMix.before_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev\n",
    "nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
