{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f9fe9d8-746e-42f0-8f02-b9d296adaa2d",
   "metadata": {},
   "source": [
    "In this group of notebook we will test the methods implemented in the library to check if they can improve the results of the models.\n",
    "\n",
    "In order to be as impartial as possible, we will use a KFold evaluation for each combination, with a k-value of five.\n",
    "\n",
    "In this particular notebook, we will train the model using the `CarveMix` technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c3700f-949f-45e5-93b1-a51ff1eab5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruescog/.conda/envs/visionmodelsevaluation/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from fastai.basics import *\n",
    "from fastai.vision import models\n",
    "from fastai.vision.all import *\n",
    "from fastai.metrics import *\n",
    "from fastai.data.all import *\n",
    "from fastai.callback import *\n",
    "\n",
    "from semantic_segmentation_augmentations.holemakerroi import HoleMakerROI\n",
    "from semantic_segmentation_augmentations.carvemix import CarveMix\n",
    "\n",
    "from vision_models_evaluation.core import evaluate\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import PIL\n",
    "import torchvision.transforms as transforms\n",
    "from pathlib import Path\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ac4f38-8a59-4174-ba46-0b7148e5f916",
   "metadata": {},
   "source": [
    "Then, we prepare the scenario: we are going to use a grape vine dataset where the semantic problem to tackle is to segmentate the RGB images into wood, leaves, grape and pole classes.\n",
    "\n",
    "Finally, we define here the mapping functions and the masks transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdbdfc5-c782-423a-bfef-bb84e00c9d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=Path('dataset/')\n",
    "path_images = path/\"Images\"\n",
    "path_labels = path/\"Labels\"\n",
    "\n",
    "def get_y_fn (x):\n",
    "    return Path(str(x).replace(\"Images\",\"Labels\").replace(\"color\",\"gt\").replace(\".jpg\",\".png\"))\n",
    "\n",
    "codes = np.loadtxt(path/'codesAll.txt', dtype=str)\n",
    "\n",
    "def ParentSplitter(x):\n",
    "    return Path(x).parent.name==test_name\n",
    "\n",
    "from albumentations import (\n",
    "  Compose,\n",
    "  OneOf,\n",
    "  ElasticTransform,\n",
    "  GridDistortion, \n",
    "  OpticalDistortion,\n",
    "  HorizontalFlip,\n",
    "  Rotate,\n",
    "  Transpose,\n",
    "  CLAHE,\n",
    "  ShiftScaleRotate\n",
    ")\n",
    "\n",
    "class SegmentationAlbumentationsTransform(ItemTransform):\n",
    "    split_idx = 0\n",
    "\n",
    "    def __init__(self, aug): \n",
    "        self.aug = aug\n",
    "\n",
    "    def encodes(self, x):\n",
    "        img,mask = x\n",
    "        aug = self.aug(image=np.array(img), mask=np.array(mask))\n",
    "        return PILImage.create(aug[\"image\"]), PILMask.create(aug[\"mask\"])\n",
    "\n",
    "transforms=Compose([HorizontalFlip(p=0.5),\n",
    "                    Rotate(p=0.40,limit=10),GridDistortion()\n",
    "                    ],p=1)\n",
    "\n",
    "transformPipeline=SegmentationAlbumentationsTransform(transforms)\n",
    "\n",
    "class TargetMaskConvertTransform(ItemTransform):\n",
    "    def __init__(self): \n",
    "        pass\n",
    "    def encodes(self, x):\n",
    "        img,mask = x\n",
    "\n",
    "        #Convert to array\n",
    "        mask = np.array(mask)\n",
    "\n",
    "        # background = 0, leaves = 1, pole = 74 o 76, wood = 25 o 29, grape = 255\n",
    "        mask[mask == 255] = 1 # grape\n",
    "        mask[mask == 150] = 2 # leaves\n",
    "        mask[mask == 76] = 3 ; mask[mask == 74] = 3 # pole\n",
    "        mask[mask == 29] = 4 ; mask[mask == 25] = 4 # wood\n",
    "        mask[mask >= 5] = 0 # resto: background\n",
    "\n",
    "        # Back to PILMask\n",
    "        mask = PILMask.create(mask)\n",
    "        return img, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71da4cae-fd44-48d3-bc50-a5d259ccb3ac",
   "metadata": {},
   "source": [
    "While training, we will use the EarlyStopping strategy: after five epoch without improvements, the training will be stopped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d61604-0aab-4708-bc91-08bbc983dffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "esc = EarlyStoppingCallback(patience = 5, min_delta = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725c9972-d7ed-49c4-9f2f-ccd00586a750",
   "metadata": {},
   "source": [
    "Then, we define all the hparams (hyperparameters) to build the datablocks, dataloaders and learners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a3e481-acc7-439b-ad6a-632b6e5115a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_hparams = {\n",
    "    \"blocks\": (ImageBlock, MaskBlock(codes)),\n",
    "    \"get_items\": get_image_files,\n",
    "    \"get_y\": get_y_fn,\n",
    "    \"splitter\": RandomSplitter(valid_pct=0.2),\n",
    "    \"item_tfms\": [Resize((480,640)), TargetMaskConvertTransform(), transformPipeline],\n",
    "    \"batch_tfms\": Normalize.from_stats(*imagenet_stats)\n",
    "}\n",
    "\n",
    "dls_hparams = {\n",
    "    \"source\": path_images,\n",
    "    \"bs\": 16\n",
    "}\n",
    "\n",
    "technique = KFold(n_splits = 5)\n",
    "\n",
    "learner_hparams = {\n",
    "    \"arch\": resnet18,\n",
    "    \"pretrained\": True,\n",
    "    \"metrics\": [DiceMulti()],\n",
    "    \"cbs\": []\n",
    "}\n",
    "\n",
    "learning_hparams = {\n",
    "    \"epochs\": 30,\n",
    "    \"base_lr\": 0.001,\n",
    "    \"freeze_epochs\": 3\n",
    "}\n",
    "\n",
    "learning_mode = \"finetune\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75ad45c-05a0-40bf-8ea7-013e1dcbb8cb",
   "metadata": {},
   "source": [
    "In order to know how does this technique work, we can show an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3456e419-4bfc-43d7-be80-b94f74c3d93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CarveMix(holes_num = 10, ROI_class = 1, delta_ratio = 1, random_position = True, p = 1)\n",
    "dls = DataBlock(**db_hparams).dataloaders(**dls_hparams)\n",
    "with Learner(dls, resnet18(), metrics=[DiceMulti()], cbs = cv) as learn:\n",
    "    learn.epoch, learn.training = 0, True\n",
    "    learn.dl = dls.train\n",
    "    b = dls.one_batch()\n",
    "    learn._split(b)\n",
    "    learn('before_train')\n",
    "    learn('before_batch')\n",
    "\n",
    "_, axs = plt.subplots(3, 3, figsize=(9, 9))\n",
    "dls.show_batch(b = (cv.x, cv.y), ctxs = axs.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cb0c4c-a99d-4ea8-83a6-2ac1e2fc0dfc",
   "metadata": {},
   "source": [
    "Finally, we test the model with distinct hparams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f40aa71-cddf-4eba-866c-26ac9ff5e5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "for holes_num in [1]: #, 3, 5]:\n",
    "    for ROI_class in [1]: #, 1]:\n",
    "        cm = CarveMix(holes_num, ROI_class)\n",
    "        learner_hparams[\"cbs\"] = [esc, cm]\n",
    "        r = evaluate(db_hparams,\n",
    "                     dls_hparams,\n",
    "                     technique,\n",
    "                     learner_hparams,\n",
    "                     learning_hparams,\n",
    "                     learning_mode\n",
    "                    )\n",
    "        results.update({\n",
    "            str(holes_num) + str(ROI_class): r[\"DiceMulti\"]\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4615d6-e095-4d5b-8049-d94586232b10",
   "metadata": {},
   "source": [
    "And plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2655d011-86b2-4f0c-a972-adede94188ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146564d1-d99a-4ea2-b94e-00d5273bbde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(df[df.columns]);\n",
    "plt.plot([i for i in range(1, len(df.columns) + 1)], df.describe().transpose()[\"std\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bce01f-21ae-4386-b8a0-da19e1117093",
   "metadata": {},
   "source": [
    "We will show its mean and standar deviation too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ca18e8-e6c1-4221-8489-4e173b30bac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().transpose()[[\"mean\", \"std\"]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-visionmodelsevaluation]",
   "language": "python",
   "name": "conda-env-.conda-visionmodelsevaluation-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
